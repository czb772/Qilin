# Qilin VLM搜索和推荐实验复现指南

## 概述

本指南将帮助您复现Qilin仓库中的VLM（Vision-Language Model）搜索和推荐实验，并说明如何将模型从Qwen2-VL替换为Qwen2.5-VL。

## 环境准备

### 1. 系统要求
- Python 3.10.16
- CUDA兼容的GPU（推荐用于神经网络模型）
- 至少16GB GPU内存（推荐24GB+用于7B模型）

### 2. 安装依赖
```bash
cd baselines
pip install -r requirements.txt
```

## 数据准备

### 1. 下载Qilin数据集
```bash
# 从Hugging Face下载数据集
# 访问: https://huggingface.co/datasets/THUIR/qilin
# 下载并解压到 datasets/qilin/ 目录
```

### 2. 下载图像资源
```bash
# 从清华云下载图像资源
# 访问: https://cloud.tsinghua.edu.cn/d/af72ab5dbba1460da6c0/
# 下载并解压到 datasets/qilin/image/ 目录
```

### 3. 下载预训练模型
```bash
# 创建模型目录
mkdir -p model

# 下载Qwen2-VL模型（原始配置）
git clone https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct model/Qwen2-VL-2B-Instruct
git clone https://huggingface.co/Qwen/Qwen2-VL-7B-Instruct model/Qwen2-VL-7B-Instruct

# 下载BERT模型
git clone https://huggingface.co/google-bert/bert-base-chinese model/bert-base-chinese
```

## 复现原始实验

### 1. 搜索任务实验

#### 使用Qwen2-VL-2B模型
```bash
cd baselines
sh scripts/run.sh --config config/search_vlm_config.yaml --cuda 0
```

#### 使用Qwen2-VL-7B模型
```bash
# 需要修改配置文件中的模型路径
sh scripts/run.sh --config config/search_vlm7B_config.yaml --cuda 0
```

### 2. 推荐任务实验

#### 使用Qwen2-VL-2B模型
```bash
sh scripts/run.sh --config config/recommendation_vlm_config.yaml --cuda 0
```

#### 使用Qwen2-VL-7B模型
```bash
sh scripts/run.sh --config config/recommendation_vlm7B_config.yaml --cuda 0
```

### 3. 监控训练过程
```bash
sh scripts/tensorboard.sh
# 访问 http://localhost:6006 查看训练日志
```

## 将模型替换为Qwen2.5-VL

### 1. 下载Qwen2.5-VL模型
```bash
# 下载Qwen2.5-VL模型
git clone https://huggingface.co/Qwen/Qwen2.5-VL-2B-Instruct model/Qwen2.5-VL-2B-Instruct
git clone https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct model/Qwen2.5-VL-7B-Instruct
```

### 2. 创建新的配置文件

#### 搜索任务 - Qwen2.5-VL-2B配置
```bash
cp baselines/config/search_vlm_config.yaml baselines/config/search_vlm_qwen25_2b_config.yaml
```

编辑 `baselines/config/search_vlm_qwen25_2b_config.yaml`：
```yaml
project_name: "search_vlm_qwen25_2b"
project_dir: "output_search_vlm_qwen25_2b"
trainer: vlm_trainer

# Model Configuration
model:
  model_name_or_path: "../model/Qwen2.5-VL-2B-Instruct/"  # 更新为Qwen2.5-VL
  tokenizer_name_or_path: "../model/Qwen2.5-VL-2B-Instruct/"  # 更新为Qwen2.5-VL
  load_from_new: false
  lora_checkpoint_dir: "vlm_qwen25_2b_checkpoints/"
  gradient_checkpointing: true
  load_in_4bit: true
  user_lora: true

# Dataset Configuration
datasets:
  dataset_name_or_path: "../datasets/qilin/"
  train_data_processor: "VLMTrainingDataProcessor"
  tokenizer_name_or_path: "../model/Qwen2.5-VL-2B-Instruct/"  # 更新为Qwen2.5-VL
  batch_size: 64
  eval_batch_size: 1
  max_length: 512
  negative_samples: 1
  use_title: true
  use_content: true

# 其他配置保持不变...
```

#### 搜索任务 - Qwen2.5-VL-7B配置
```bash
cp baselines/config/search_vlm_config.yaml baselines/config/search_vlm_qwen25_7b_config.yaml
```

编辑 `baselines/config/search_vlm_qwen25_7b_config.yaml`：
```yaml
project_name: "search_vlm_qwen25_7b"
project_dir: "output_search_vlm_qwen25_7b"
trainer: vlm_trainer

# Model Configuration
model:
  model_name_or_path: "../model/Qwen2.5-VL-7B-Instruct/"  # 更新为Qwen2.5-VL-7B
  tokenizer_name_or_path: "../model/Qwen2.5-VL-7B-Instruct/"  # 更新为Qwen2.5-VL-7B
  load_from_new: false
  lora_checkpoint_dir: "vlm_qwen25_7b_checkpoints/"
  gradient_checkpointing: true
  load_in_4bit: true
  user_lora: true

# Dataset Configuration
datasets:
  dataset_name_or_path: "../datasets/qilin/"
  train_data_processor: "VLMTrainingDataProcessor"
  tokenizer_name_or_path: "../model/Qwen2.5-VL-7B-Instruct/"  # 更新为Qwen2.5-VL-7B
  batch_size: 32  # 可能需要减小batch size
  eval_batch_size: 1
  max_length: 512
  negative_samples: 1
  use_title: true
  use_content: true

# 其他配置保持不变...
```

#### 推荐任务 - Qwen2.5-VL-2B配置
```bash
cp baselines/config/recommendation_vlm_config.yaml baselines/config/recommendation_vlm_qwen25_2b_config.yaml
```

编辑 `baselines/config/recommendation_vlm_qwen25_2b_config.yaml`：
```yaml
project_name: "recommendation_vlm_qwen25_2b"
project_dir: "output_recommendation_vlm_qwen25_2b"
trainer: vlm_trainer

# Model Configuration
model:
  model_name_or_path: "../model/Qwen2.5-VL-2B-Instruct/"  # 更新为Qwen2.5-VL
  tokenizer_name_or_path: "../model/Qwen2.5-VL-2B-Instruct/"  # 更新为Qwen2.5-VL
  load_from_new: false
  lora_checkpoint_dir: "vlm_qwen25_2b_checkpoints/"
  user_lora: true
  load_in_4bit: true
  gradient_checkpointing: true

# Dataset Configuration
datasets:
  dataset_name_or_path: "../datasets/qilin/"
  train_data_processor: "VLMTrainingDataProcessor"
  tokenizer_name_or_path: "../model/Qwen2.5-VL-2B-Instruct/"  # 更新为Qwen2.5-VL
  batch_size: 8
  eval_batch_size: 1
  max_length: 1024
  negative_samples: 1
  use_title: true
  use_content: true
  negative_pool: rec_result_details_with_idx
  train_data_key: recommendation_train
  use_recent_clicked_note_images: true

# 其他配置保持不变...
```

#### 推荐任务 - Qwen2.5-VL-7B配置
```bash
cp baselines/config/recommendation_vlm_config.yaml baselines/config/recommendation_vlm_qwen25_7b_config.yaml
```

编辑 `baselines/config/recommendation_vlm_qwen25_7b_config.yaml`：
```yaml
project_name: "recommendation_vlm_qwen25_7b"
project_dir: "output_recommendation_vlm_qwen25_7b"
trainer: vlm_trainer

# Model Configuration
model:
  model_name_or_path: "../model/Qwen2.5-VL-7B-Instruct/"  # 更新为Qwen2.5-VL-7B
  tokenizer_name_or_path: "../model/Qwen2.5-VL-7B-Instruct/"  # 更新为Qwen2.5-VL-7B
  load_from_new: false
  lora_checkpoint_dir: "vlm_qwen25_7b_checkpoints/"
  user_lora: true
  load_in_4bit: true
  gradient_checkpointing: true

# Dataset Configuration
datasets:
  dataset_name_or_path: "../datasets/qilin/"
  train_data_processor: "VLMTrainingDataProcessor"
  tokenizer_name_or_path: "../model/Qwen2.5-VL-7B-Instruct/"  # 更新为Qwen2.5-VL-7B
  batch_size: 4  # 可能需要减小batch size
  eval_batch_size: 1
  max_length: 1024
  negative_samples: 1
  use_title: true
  use_content: true
  negative_pool: rec_result_details_with_idx
  train_data_key: recommendation_train
  use_recent_clicked_note_images: true

# 其他配置保持不变...
```

### 3. 运行Qwen2.5-VL实验

#### 搜索任务
```bash
# 使用Qwen2.5-VL-2B
sh scripts/run.sh --config config/search_vlm_qwen25_2b_config.yaml --cuda 0

# 使用Qwen2.5-VL-7B
sh scripts/run.sh --config config/search_vlm_qwen25_7b_config.yaml --cuda 0
```

#### 推荐任务
```bash
# 使用Qwen2.5-VL-2B
sh scripts/run.sh --config config/recommendation_vlm_qwen25_2b_config.yaml --cuda 0

# 使用Qwen2.5-VL-7B
sh scripts/run.sh --config config/recommendation_vlm_qwen25_7b_config.yaml --cuda 0
```

## 重要注意事项

### 1. 模型兼容性
- Qwen2.5-VL与Qwen2-VL在架构上基本兼容
- 主要区别在于模型权重和可能的tokenizer更新
- 如果遇到兼容性问题，可能需要调整模型加载代码

### 2. 内存管理
- Qwen2.5-VL-7B需要更多GPU内存
- 如果遇到OOM错误，可以：
  - 减小batch_size
  - 启用gradient_checkpointing
  - 使用load_in_4bit=True
  - 使用多GPU训练

### 3. 训练参数调整
- 可能需要调整学习率
- 根据模型性能调整训练步数
- 监控验证集性能避免过拟合

### 4. 评估指标
- 主要评估指标：MRR@10
- 其他指标：NDCG@10, Recall@10, Precision@10
- 结果保存在eval_results目录

## 故障排除

### 1. 常见错误
- **CUDA内存不足**：减小batch_size或使用gradient_checkpointing
- **模型加载失败**：检查模型路径和文件完整性
- **数据加载错误**：检查数据集路径和格式

### 2. 性能优化
- 使用混合精度训练
- 启用gradient_checkpointing
- 使用LoRA进行高效微调

### 3. 调试技巧
- 使用tensorboard监控训练过程
- 检查日志文件中的错误信息
- 使用小数据集进行快速测试

## 预期结果

使用Qwen2.5-VL应该能够获得比Qwen2-VL更好的性能，特别是在：
- 多模态理解能力
- 文本-图像对齐
- 搜索和推荐准确性

建议对比两种模型在相同配置下的性能表现。
